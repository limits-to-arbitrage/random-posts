# Notes on *Introduction to Statistical Learning with Applications in Python*
This is a place to share notes on my read through *Introduction to Statistical Learning with Applications in Python*, which text is available [here](https://www.statlearning.com/).

## Index
* [Walking through the reducible/irreducible error math on page 18](https://github.com/limits-to-arbitrage/random-posts/tree/main/notes_islp/reducible_math): On page 18, when discussing the difference between reducible and irreducible error, the text notes that $E(Y-\hat{Y})^2=\big(f(X)-\hat{f}(X)\big)^2+Var(\varepsilon)$, stating this equality is "easy to show". This post walks through how to do so.
* [Deriving the bias-variance trade-off formula on page 32](UPDATE): On page 32, the formula for the bias-variance trade-off (for MSE) is stated, but its derivation is not provided. This post provides a simple derivation.
